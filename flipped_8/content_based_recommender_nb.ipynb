{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4710dbc4",
   "metadata": {},
   "source": [
    "# Content-Based Recommender System using Naive Bayes\n",
    "\n",
    "This notebook implements two types of content-based recommendation systems using the MovieLens dataset:\n",
    "1. User-specific recommender using Naive Bayes (user profile models)\n",
    "2. Global recommender using Kronecker product of user/item features\n",
    "3. Evaluation methodology for realistic recommendation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c70de",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8227934",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ratings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ratings_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mratings.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m movies_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mmovies.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m tags_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mtags.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/DataAnaCla25/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/DataAnaCla25/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/DataAnaCla25/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/DataAnaCla25/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/DataAnaCla25/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'ratings.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_PATH = \"../ml-latest-small\"\n",
    "\n",
    "ratings_df = pd.read_csv(os.path.join(DATA_PATH, \"ratings.csv\"))\n",
    "movies_df = pd.read_csv(os.path.join(DATA_PATH, \"movies.csv\"))\n",
    "tags_df = pd.read_csv(os.path.join(DATA_PATH, \"tags.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b09c64",
   "metadata": {},
   "source": [
    "### Merge and clean metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_agg = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "movies_meta = pd.merge(movies_df, tags_agg, on='movieId', how='left')\n",
    "movies_meta['tag'] = movies_meta['tag'].fillna('')\n",
    "movies_meta['content'] = movies_meta['genres'].str.replace('|', ' ') + ' ' + movies_meta['tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb22e10",
   "metadata": {},
   "source": [
    "## 2. User-Specific Recommender using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de669c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def train_user_model(user_id, top_k=10):\n",
    "    user_data = ratings_df[ratings_df['userId'] == user_id]\n",
    "    rated_items = pd.merge(user_data, movies_meta, on='movieId')\n",
    "    \n",
    "    rated_items['label'] = rated_items['rating'].apply(lambda r: 1 if r >= 4 else (0 if r <= 2 else None))\n",
    "    rated_items = rated_items.dropna(subset=['label']).copy()\n",
    "    rated_items['label'] = rated_items['label'].astype(int)\n",
    "\n",
    "    if rated_items.empty:\n",
    "        return None\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X = tfidf.fit_transform(rated_items['content'])\n",
    "    y = rated_items['label']\n",
    "\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    seen_ids = user_data['movieId'].unique()\n",
    "    candidate_pool = movies_meta[~movies_meta['movieId'].isin(seen_ids)]\n",
    "    X_test = tfidf.transform(candidate_pool['content'])\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    candidate_pool = candidate_pool.copy()\n",
    "    candidate_pool['score'] = probs\n",
    "\n",
    "    return candidate_pool[['movieId', 'title', 'score']].sort_values('score', ascending=False).head(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1dd69f",
   "metadata": {},
   "source": [
    "### ðŸ” Test it with a user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ec978",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_user = train_user_model(user_id=1)\n",
    "recommendations_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c9617",
   "metadata": {},
   "source": [
    "## 3. Global Recommender using Kronecker Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e54c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "user_tags = tags_df.groupby('userId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "user_tags['tag'] = user_tags['tag'].fillna('')\n",
    "\n",
    "item_vectorizer = TfidfVectorizer(max_features=100)\n",
    "item_vectors = item_vectorizer.fit_transform(movies_meta['content'])\n",
    "item_df = pd.DataFrame(item_vectors.toarray(), index=movies_meta['movieId'])\n",
    "\n",
    "user_vectorizer = TfidfVectorizer(max_features=100)\n",
    "user_vectors = user_vectorizer.fit_transform(user_tags['tag'])\n",
    "user_df = pd.DataFrame(user_vectors.toarray(), index=user_tags['userId'])\n",
    "\n",
    "def kronecker(user_vec, item_vec):\n",
    "    return np.kron(user_vec, item_vec)\n",
    "\n",
    "train_data = []\n",
    "labels = []\n",
    "\n",
    "for _, row in ratings_df.iterrows():\n",
    "    if row['userId'] not in user_df.index or row['movieId'] not in item_df.index:\n",
    "        continue\n",
    "\n",
    "    user_vec = user_df.loc[row['userId']].values\n",
    "    item_vec = item_df.loc[row['movieId']].values\n",
    "    vec = kronecker(user_vec, item_vec)\n",
    "\n",
    "    if row['rating'] >= 4:\n",
    "        label = 1\n",
    "    elif row['rating'] <= 2:\n",
    "        label = 0\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    train_data.append(vec)\n",
    "    labels.append(label)\n",
    "\n",
    "X_global = np.vstack(train_data)\n",
    "y_global = np.array(labels)\n",
    "\n",
    "model_global = MultinomialNB()\n",
    "model_global.fit(X_global, y_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36492bf",
   "metadata": {},
   "source": [
    "### ðŸ” Global Recommendation for User:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e872c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_global(user_id, top_k=10):\n",
    "    if user_id not in user_df.index:\n",
    "        return []\n",
    "\n",
    "    user_vec = user_df.loc[user_id].values\n",
    "    seen = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    candidates = item_df[~item_df.index.isin(seen)]\n",
    "\n",
    "    features = np.vstack([kronecker(user_vec, item_vec) for item_vec in candidates.values])\n",
    "    probs = model_global.predict_proba(features)[:, 1]\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'movieId': candidates.index,\n",
    "        'score': probs\n",
    "    }).merge(movies_df[['movieId', 'title']], on='movieId')\n",
    "\n",
    "    return results.sort_values('score', ascending=False).head(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4807350c",
   "metadata": {},
   "source": [
    "### ðŸ” Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_global = recommend_global(user_id=1)\n",
    "recommendations_global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e803c",
   "metadata": {},
   "source": [
    "## 4. Evaluation Methodology (Candidate Pool Strategy)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "def evaluate_user(user_id):\n",
    "    user_data = ratings_df[ratings_df['userId'] == user_id]\n",
    "    if len(user_data) < 5:\n",
    "        return None\n",
    "\n",
    "    train, test = train_test_split(user_data, test_size=0.4, random_state=42)\n",
    "    train_model_data = pd.merge(train, movies_meta, on='movieId')\n",
    "\n",
    "    train_model_data['label'] = train_model_data['rating'].apply(lambda r: 1 if r >= 4 else (0 if r <= 2 else None))\n",
    "    train_model_data = train_model_data.dropna(subset=['label'])\n",
    "    train_model_data['label'] = train_model_data['label'].astype(int)\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X_train = tfidf.fit_transform(train_model_data['content'])\n",
    "    y_train = train_model_data['label']\n",
    "\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    test_data = pd.merge(test, movies_meta, on='movieId')\n",
    "    X_test = tfidf.transform(test_data['content'])\n",
    "    y_test = test_data['rating'].apply(lambda r: 1 if r >= 4 else 0)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    return {\"user_id\": user_id, \"precision\": precision, \"roc_auc\": auc}\n",
    "\n",
    "evaluate_user(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9e5ba",
   "metadata": {},
   "source": [
    "## âœ… Done!\n",
    "You now have both user-specific and global content-based recommendation systems, along with a realistic evaluation setup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
